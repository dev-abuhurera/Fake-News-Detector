Fake News Detector

This project is an AI-based model that can detect whether a news article is fake or real using machine learning.

What You Need

âœ… Python Installed (Recommended version 3.8 or later)

âœ… Required Libraries (Install them later):

pandas
numpy
sklearn
flask
spacy
joblib

âœ… Datasets Required:

True.csv (Real news dataset)
Fake.csv (Fake news dataset)

Step-by-Step Setup

1. Get the Project
 Download or clone the repository from GitHub.
 
 Open the folder where the project is saved.

2. Set Up the Environment
  Create a separate Python environment to keep the project organized.

 Activate the environment before running the project.

4. Install Required Libraries
   Run the following command to install dependencies:

bash...
Copy code

pip install -r requirements.txt
(This will install all required libraries automatically.)

4. Download the Required Model
âš ï¸ The project uses spaCy for text processing. If you havenâ€™t installed the necessary language model, run:

bash...

Copy code
python -m spacy download en_core_web_sm
(This will download the required NLP model.)

5. Run the Application
ğŸ“Œ Start training the model by running:

bash


Copy code
python fake_news_detector.py --true path/to/True.csv --fake path/to/Fake.csv
(Replace path/to/True.csv and path/to/Fake.csv with actual file paths.)

6. Open the Web App
ğŸŒ Use a web browser to access the interface and enter news text.

7. Use the Model
ğŸ“ Enter or upload a news article.
ğŸ”˜ Click the Predict button.
ğŸ¤– The model will classify the news as Fake or Real.

8. (Optional) Train the Model Again
ğŸ’¡ You can retrain the model using different datasets if needed.
ğŸ“Œ The trained model and vectorizer are saved in:

fake_news_model.pkl
vectorizer.pkl
If you want to retrain the model, simply delete these files and rerun the training command.

9. Close the Environment After Use
ğŸ’¡ If you used a virtual environment, deactivate it when youâ€™re done:

bash
Copy code
deactivate
Changes and Improvements in This Version
ğŸ”¹ Added NLP Preprocessing Using spaCy

The text is cleaned, tokenized, and lemmatized before training.
Stop words are removed for better accuracy.
ğŸ”¹ Optimized Data Handling

The script ensures that the "text" column exists in the dataset.
If missing, it combines the "title" column as a fallback.
ğŸ”¹ Improved Training Process

Uses TF-IDF Vectorization to convert text into numerical form.
Uses RandomForestClassifier with better hyperparameters for accuracy.
Prevents overfitting using min_samples_leaf=2 and max_features='sqrt'.
ğŸ”¹ Ensured Model and Vectorizer Are Saved Properly

Saves both in pickle format (.pkl) for easy reusability.
ğŸ”¹ User Can Choose Testing Data

Instead of hardcoding, users provide their own dataset paths while running the script.
